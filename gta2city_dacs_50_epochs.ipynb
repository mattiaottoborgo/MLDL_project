{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8497954,
          "sourceType": "datasetVersion",
          "datasetId": 5070943
        },
        {
          "sourceId": 8504453,
          "sourceType": "datasetVersion",
          "datasetId": 5075886
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "gta2city_dacs",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-23T16:04:36.143401Z",
          "iopub.execute_input": "2024-05-23T16:04:36.143787Z"
        },
        "id": "ZcEWWVRDTC0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#execute just the first time to move scripts and dataset from input to output\n",
        "import sys\n",
        "from shutil import copytree, copyfile\n",
        "sys.path.append(\"/kaggle/input/gta-dacs/\")\n",
        "\n",
        "src_datasets='/kaggle/input/gta-dacs/datasets'\n",
        "dst_datasets='/kaggle/working/datasets/'\n",
        "copytree(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/models'\n",
        "dst_datasets='/kaggle/working/models/'\n",
        "copytree(src_datasets, dst_datasets)\n",
        "#sys.path.append(\"/kaggle/input/cityscapes/\")\n",
        "\n",
        "# src_datasets='/kaggle/input/cityscapes/deeplab_resnet_pretrained_imagenet.pth'\n",
        "# dst_datasets='/kaggle/working/deeplab_resnet_pretrained_imagenet.pth'\n",
        "# copyfile(src_datasets, dst_datasets)\n",
        "\n",
        "src_datasets='/kaggle/input/gta-dacs/transformmasks.py'\n",
        "dst_datasets='/kaggle/working/transformmasks.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/transformsgpu.py'\n",
        "dst_datasets='/kaggle/working/transformgpu.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "\n",
        "\n",
        "copyfile(src = \"/kaggle/input/gta-dacs/utils.py\", dst = \"/kaggle/working/utils.py\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:33:47.92838Z",
          "iopub.execute_input": "2024-05-24T08:33:47.928716Z",
          "iopub.status.idle": "2024-05-24T08:33:50.526451Z",
          "shell.execute_reply.started": "2024-05-24T08:33:47.928689Z",
          "shell.execute_reply": "2024-05-24T08:33:50.525411Z"
        },
        "trusted": true,
        "id": "KfNuEQd8TC0Z",
        "outputId": "affb54f9-2648-4976-a55f-c10ed571df6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/utils.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_datasets='/kaggle/input/gta-dacs/transformmasks.py'\n",
        "dst_datasets='/kaggle/working/transformmasks.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/transformsgpu.py'\n",
        "dst_datasets='/kaggle/working/transformgpu.py'\n",
        "copyfile(src_datasets, dst_datasets)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T16:09:12.068676Z",
          "iopub.execute_input": "2024-05-23T16:09:12.069268Z",
          "iopub.status.idle": "2024-05-23T16:09:12.078488Z",
          "shell.execute_reply.started": "2024-05-23T16:09:12.069236Z",
          "shell.execute_reply": "2024-05-23T16:09:12.077749Z"
        },
        "trusted": true,
        "id": "d37UI3AFTC0a",
        "outputId": "d4130b16-016a-47cf-a4ae-8470fc0a1005"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/transformgpu.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.gta5 import GTA5\n",
        "from datasets.cityscapes import CityScapes\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import transformmasks\n",
        "import transformsgpu\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import posixpath\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from utils import poly_lr_scheduler\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "\n",
        "def strong_transform(parameters, data=None, target=None):\n",
        "    assert ((data is not None) or (target is not None))\n",
        "    data, target = transformsgpu.oneMix(mask=parameters[\"Mix\"], data=data, target=target)\n",
        "    data, target = transformsgpu.colorJitter(colorJitter=parameters[\"ColorJitter\"], img_mean=torch.from_numpy(IMG_MEAN.copy()).to(device), data=data, target=target)\n",
        "    data, target = transformsgpu.gaussian_blur(blur=parameters[\"GaussianBlur\"], data=data, target=target)\n",
        "    data, target = transformsgpu.flip(flip=parameters[\"flip\"], data=data, target=target)\n",
        "    return data, target\n",
        "\n",
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=19):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                #print(\"true class size\",true_class.shape)\n",
        "                #print(\"true label size\",true_label.shape)\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)\n",
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        correct = torch.eq(output, mask).int()\n",
        "        accuracy = float(correct.sum()) / float(correct.numel())\n",
        "    return accuracy\n",
        "\n",
        "def convert_tensor_to_image(tensor):\n",
        "    image = tensor.permute(1, 2, 0)\n",
        "    return image\n",
        "\n",
        "def train(model, optimizer, train_loader, target_loader, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    iou_score = 0.0\n",
        "    accuracy = 0.0\n",
        "    ii = 0\n",
        "\n",
        "    target_iter = iter(target_loader)\n",
        "    max_target_iter=250\n",
        "    target_counter=0\n",
        "    for batch_idx, source_batch in enumerate(train_loader):\n",
        "        if target_counter >= max_target_iter:\n",
        "            target_iter = iter(target_loader)\n",
        "            target_counter = 0\n",
        "        ii += 1\n",
        "\n",
        "        try:\n",
        "            target_batch = next(target_iter)\n",
        "        except StopIteration:\n",
        "            target_iter = iter(target_loader)\n",
        "            target_batch = next(target_iter)\n",
        "        target_counter+=1\n",
        "        inputs, targets = source_batch\n",
        "        target_inputs, _ = target_batch\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.squeeze()\n",
        "        target_inputs = target_inputs.to(device).float()\n",
        "\n",
        "        # Step 5: Generate pseudo-labels for target domain images\n",
        "        with torch.no_grad():\n",
        "            logits_u_w = model(target_inputs)[0]\n",
        "            pseudo_label = torch.softmax(logits_u_w, dim=1)\n",
        "            max_probs, targets_u_w = torch.max(pseudo_label, dim=1)\n",
        "\n",
        "        # Step 6: Create mixed images and pseudo-labels\n",
        "        batch_size = inputs.size(0)\n",
        "        MixMask = []\n",
        "        for image_i in range(batch_size):\n",
        "            classes = torch.unique(targets[image_i])\n",
        "            nclasses = classes.shape[0]\n",
        "            selected_classes = classes[torch.Tensor(np.random.choice(nclasses, int((nclasses + nclasses % 2) / 2), replace=False)).long()].to(device)\n",
        "            MixMask.append(transformmasks.generate_class_mask(targets[image_i], selected_classes).unsqueeze(0).to(device))\n",
        "\n",
        "        inputs_u_s_list, targets_u_s_list = [], []\n",
        "        for i, mask in enumerate(MixMask):\n",
        "            strong_parameters = {\"Mix\": mask, \"ColorJitter\": 0.2, \"GaussianBlur\": 0.5, \"flip\": 0.5}\n",
        "            inputs_u_s, targets_u_s = strong_transform(strong_parameters, data=torch.cat((inputs[i].unsqueeze(0), target_inputs[i].unsqueeze(0))), target=torch.cat((targets[i].unsqueeze(0), targets_u_w[i].unsqueeze(0))))\n",
        "            inputs_u_s_list.append(inputs_u_s)\n",
        "            targets_u_s_list.append(targets_u_s)\n",
        "\n",
        "        inputs_u_s = torch.cat(inputs_u_s_list)\n",
        "        targets_u_s = torch.cat(targets_u_s_list)\n",
        "\n",
        "        # Step 7: Compute predictions for mixed images\n",
        "        logits_u_s = model(inputs_u_s)[0]\n",
        "        L_u = F.cross_entropy(logits_u_s, targets_u_s, ignore_index=255, reduction='none')\n",
        "        mask = max_probs.ge(0.968).float()\n",
        "        L_u = (L_u * mask).mean()\n",
        "\n",
        "        # Compute predictions for source images\n",
        "        outputs, _, _ = model(inputs)\n",
        "        L_s = criterion(outputs.to(dtype=torch.float32), targets.to(dtype=torch.int64))\n",
        "\n",
        "        # Combine supervised and unsupervised losses\n",
        "        loss = L_s + L_u\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        iou_score += mIoU(outputs.to(device), targets.to(device))\n",
        "        accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    iou_score = iou_score / len(train_loader)\n",
        "    accuracy = accuracy / len(train_loader)\n",
        "    return train_loss, iou_score, accuracy\n",
        "# Test loop\n",
        "# calculate_label_prediction is a flag used to decide wether to calculate or not ground_truth and predicted tensor\n",
        "def test(model, test_loader, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    iou_score=0.0\n",
        "    accuracy=0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx,(inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            inputs = inputs.float()\n",
        "            targets = targets.int()\n",
        "            #Compute prediction and loss\n",
        "            outputs = model(inputs)\n",
        "            #print(batch_idx)\n",
        "            loss = loss_fn(outputs.to(dtype=torch.float32), targets.squeeze().to(dtype=torch.int64))\n",
        "            iou_score += mIoU(outputs.to(device), targets.to(device))\n",
        "            accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
        "            test_loss += loss.item()\n",
        "            #break\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    iou_score = iou_score / len(test_loader)\n",
        "    accuracy = accuracy / len(test_loader)\n",
        "    #test_accuracy = 100. * correct / total\n",
        "    return test_loss,iou_score,accuracy\n",
        "\n",
        "print(CityScapes)\n",
        "#dataset_path='/kaggle/input/cityscapes-polito/Cityscapes/Cityscapes/Cityspaces/'\n",
        "gta_dataset_path='/kaggle/input/gta-dacs/GTA5/GTA5/GTA5/'\n",
        "annotation_train=gta_dataset_path+'labels_correct/'\n",
        "image_train=gta_dataset_path+'images/'\n",
        "cityscapes_dataset_path='/kaggle/input/gta-dacs/Cityscapes/Cityscapes/Cityspaces/'\n",
        "annotation_val=cityscapes_dataset_path+'gtFine/val'\n",
        "image_val=cityscapes_dataset_path+'images/val'\n",
        "annotation_val_train=cityscapes_dataset_path+'gtFine/train'\n",
        "image_val_train=cityscapes_dataset_path+'images/train'\n",
        "resize_transform_gta = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (720,1280))\n",
        "resize_transform = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (512,1024))\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "applier_crop = v2.RandomApply(transforms=[v2.RandomCrop(size=(512, 1024))], p=0.5)\n",
        "gta_train = GTA5(annotations_dir=annotation_train, images_dir=image_train,transform=resize_transform,applier=applier_crop)\n",
        "cityscapes_val = CityScapes(annotations_dir=annotation_val, images_dir=image_val,transform=resize_transform,applier=applier_crop)\n",
        "cityscapes_train=CityScapes(annotations_dir=annotation_val_train, images_dir=image_val_train,transform=resize_transform,applier=applier_crop)\n",
        "train_loader = DataLoader(gta_train, batch_size=2, shuffle=False)\n",
        "val_loader = DataLoader(cityscapes_val, batch_size=2, shuffle=False)\n",
        "train_loader_cityscapes= DataLoader(cityscapes_train, batch_size=2, shuffle=False)\n",
        "# Define the model and load it to the device\n",
        "bisenet = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "bisenet.to(device)\n",
        "optimizer = torch.optim.Adam(bisenet.parameters(), lr=0.001)\n",
        "scheduler=poly_lr_scheduler(optimizer, 0.01, 1, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "epoch_beginning=0\n",
        "epochs = 50"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:47:49.781923Z",
          "iopub.execute_input": "2024-05-24T08:47:49.78228Z",
          "iopub.status.idle": "2024-05-24T08:47:56.300765Z",
          "shell.execute_reply.started": "2024-05-24T08:47:49.782251Z",
          "shell.execute_reply": "2024-05-24T08:47:56.299771Z"
        },
        "trusted": true,
        "id": "K-FQQpg3TC0b",
        "outputId": "1fac6680-2647-4b95-a11e-8f99d4faceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'datasets.cityscapes.CityScapes'>\ncuda\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_cityscapes.dataset.__len__()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:46:10.251268Z",
          "iopub.execute_input": "2024-05-24T08:46:10.251692Z",
          "iopub.status.idle": "2024-05-24T08:46:10.257661Z",
          "shell.execute_reply.started": "2024-05-24T08:46:10.251663Z",
          "shell.execute_reply": "2024-05-24T08:46:10.256704Z"
        },
        "trusted": true,
        "id": "O-RZkpsyTC0c",
        "outputId": "b59cfcca-f445-4856-9236-c46a51c22b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1572"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model and load it to the device\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model.to(device)\n",
        "epoch = 0 #to initialize the lr\n",
        "start_lr = 1e-2\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
        "l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:46:30.903237Z",
          "iopub.execute_input": "2024-05-24T08:46:30.904057Z",
          "iopub.status.idle": "2024-05-24T08:46:32.234775Z",
          "shell.execute_reply.started": "2024-05-24T08:46:30.904025Z",
          "shell.execute_reply": "2024-05-24T08:46:32.233969Z"
        },
        "trusted": true,
        "id": "1fAhzosdTC0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IivEUReeTC0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze model parameters, but in avery fancy way\n",
        "for index,param in enumerate(model.parameters()):\n",
        "    if index < 75:\n",
        "        param.requires_grad=False\n",
        "#         print(index)\n",
        "for param in model.attention_refinement_module2.parameters():\n",
        "    param.requires_grad=False\n",
        "for param in model.feature_fusion_module.parameters():\n",
        "    param.requires_grad=True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:46:33.925934Z",
          "iopub.execute_input": "2024-05-24T08:46:33.926305Z",
          "iopub.status.idle": "2024-05-24T08:46:33.932651Z",
          "shell.execute_reply.started": "2024-05-24T08:46:33.926278Z",
          "shell.execute_reply": "2024-05-24T08:46:33.931708Z"
        },
        "trusted": true,
        "id": "YUj77Fq-TC0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iou_list=[]\n",
        "train_acc_list=[]\n",
        "train_loss_list=[]\n",
        "test_iou_list=[]\n",
        "class_iou_list=[]\n",
        "test_acc_list=[]\n",
        "test_loss_list=[]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:59:36.343415Z",
          "iopub.execute_input": "2024-05-24T08:59:36.344225Z",
          "iopub.status.idle": "2024-05-24T08:59:36.349001Z",
          "shell.execute_reply.started": "2024-05-24T08:59:36.344192Z",
          "shell.execute_reply": "2024-05-24T08:59:36.347973Z"
        },
        "trusted": true,
        "id": "XA4eIOD9TC0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_datasets='/kaggle/input/weights-10-epoch/bisenet_GTA5_bs2_epoch10_weights.pth'\n",
        "dst_datasets='/kaggle/working/bisenet_GTA5_bs2_epoch10_weights.pth'\n",
        "copyfile(src_datasets, dst_datasets)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:44:02.697922Z",
          "iopub.execute_input": "2024-05-24T08:44:02.698626Z",
          "iopub.status.idle": "2024-05-24T08:44:03.220672Z",
          "shell.execute_reply.started": "2024-05-24T08:44:02.698595Z",
          "shell.execute_reply": "2024-05-24T08:44:03.219769Z"
        },
        "trusted": true,
        "id": "Skh88l-pTC0g",
        "outputId": "f3359f89-7594-4f1c-d5e8-426553afb52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/bisenet_GTA5_bs2_epoch10_weights.pth'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifica il percorso del file dei pesi salvati\n",
        "checkpoint_path = \"bisenet_GTA5_bs2_epoch10_weights.pth\"  # Aggiorna con il percorso corretto\n",
        "\n",
        "# Carica i pesi nel modello\n",
        "model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:46:57.607589Z",
          "iopub.execute_input": "2024-05-24T08:46:57.607948Z",
          "iopub.status.idle": "2024-05-24T08:46:57.674902Z",
          "shell.execute_reply.started": "2024-05-24T08:46:57.607918Z",
          "shell.execute_reply": "2024-05-24T08:46:57.673942Z"
        },
        "trusted": true,
        "id": "j4NEW1fmTC0h",
        "outputId": "617e8892-c9c8-45d5-af72-d20bbed39092"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "bs=2\n",
        "epoch_beginning = 10\n",
        "epochs = 51\n",
        "for epoch in range(epoch_beginning,epochs):\n",
        "    n_epoch = epoch+1\n",
        "    l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "    #train\n",
        "    train_loss,train_iou,train_acc=train(model, optimizer, train_loader,train_loader_cityscapes, loss_fn)\n",
        "    train_iou = np.nanmean(train_iou)\n",
        "    train_iou_list.append(train_iou)\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    #save model\n",
        "    if n_epoch%5 == 0 or n_epoch==epochs:\n",
        "        model_name = f\"bisenet_GTA5_bs{bs}_epoch{n_epoch}_weights.pth\"\n",
        "        torch.save(model.state_dict(), model_name)\n",
        "\n",
        "    #test\n",
        "    test_loss,class_iou,test_acc = test(model, val_loader, loss_fn)\n",
        "    test_iou = np.nanmean(class_iou)\n",
        "    test_iou_list.append(test_iou)\n",
        "    class_iou_list.append(class_iou)\n",
        "    test_acc_list.append(test_acc)\n",
        "    test_loss_list.append(test_loss)\n",
        "\n",
        "    f = open(\"train_iou_list.txt\", \"a\")\n",
        "    f.write(str(train_iou)+ \"\\n\")\n",
        "    f.close()\n",
        "    f = open(\"test_iou_list.txt\", \"a\")\n",
        "    f.write(str(test_iou)+ \"\\n\")\n",
        "    f.close()\n",
        "\n",
        "    print(f\"Epoch: {n_epoch}\")\n",
        "    print(f\"- Train Acc: {train_acc:.3f}\")\n",
        "#     print(f\"- Train Loss: {test_loss:.3f}\")\n",
        "    print(f\"- Train mIoU: {train_iou:.3f}\\n\")\n",
        "    print(f\"- Test Acc: {test_acc:.3f}\")\n",
        "    print(f\"- Test Loss: {test_loss:.3f}\")\n",
        "    print(f\"- Test mIoU: {test_iou:.3f}\")\n",
        "    if n_epoch==1 or n_epoch == epochs:\n",
        "        print(f\"- Iou per Class: {class_iou}\")\n",
        "    print(\"__________________________\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-24T08:59:41.50736Z",
          "iopub.execute_input": "2024-05-24T08:59:41.50808Z",
          "iopub.status.idle": "2024-05-24T15:05:39.455521Z",
          "shell.execute_reply.started": "2024-05-24T08:59:41.508044Z",
          "shell.execute_reply": "2024-05-24T15:05:39.454558Z"
        },
        "trusted": true,
        "id": "WJKZKIGcTC0h",
        "outputId": "5e8f9a84-5af4-42dc-ea30-675e11fae664"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch: 11\n- Train Acc: 0.489\n- Train mIoU: 0.257\n\n- Test Acc: 0.321\n- Test Loss: 1.208\n- Test mIoU: 0.184\n__________________________\nEpoch: 12\n- Train Acc: 0.476\n- Train mIoU: 0.252\n\n- Test Acc: 0.322\n- Test Loss: 1.286\n- Test mIoU: 0.178\n__________________________\nEpoch: 13\n- Train Acc: 0.470\n- Train mIoU: 0.250\n\n- Test Acc: 0.318\n- Test Loss: 1.185\n- Test mIoU: 0.186\n__________________________\nEpoch: 14\n- Train Acc: 0.480\n- Train mIoU: 0.254\n\n- Test Acc: 0.332\n- Test Loss: 1.203\n- Test mIoU: 0.187\n__________________________\nEpoch: 15\n- Train Acc: 0.476\n- Train mIoU: 0.255\n\n- Test Acc: 0.334\n- Test Loss: 1.112\n- Test mIoU: 0.188\n__________________________\nEpoch: 16\n- Train Acc: 0.474\n- Train mIoU: 0.254\n\n- Test Acc: 0.327\n- Test Loss: 1.224\n- Test mIoU: 0.189\n__________________________\nEpoch: 17\n- Train Acc: 0.467\n- Train mIoU: 0.251\n\n- Test Acc: 0.311\n- Test Loss: 1.179\n- Test mIoU: 0.182\n__________________________\nEpoch: 18\n- Train Acc: 0.483\n- Train mIoU: 0.256\n\n- Test Acc: 0.311\n- Test Loss: 1.150\n- Test mIoU: 0.187\n__________________________\nEpoch: 19\n- Train Acc: 0.485\n- Train mIoU: 0.256\n\n- Test Acc: 0.317\n- Test Loss: 1.157\n- Test mIoU: 0.185\n__________________________\nEpoch: 20\n- Train Acc: 0.477\n- Train mIoU: 0.252\n\n- Test Acc: 0.339\n- Test Loss: 1.145\n- Test mIoU: 0.192\n__________________________\nEpoch: 21\n- Train Acc: 0.473\n- Train mIoU: 0.254\n\n- Test Acc: 0.315\n- Test Loss: 1.245\n- Test mIoU: 0.184\n__________________________\nEpoch: 22\n- Train Acc: 0.475\n- Train mIoU: 0.254\n\n- Test Acc: 0.310\n- Test Loss: 1.346\n- Test mIoU: 0.178\n__________________________\nEpoch: 23\n- Train Acc: 0.478\n- Train mIoU: 0.256\n\n- Test Acc: 0.322\n- Test Loss: 1.223\n- Test mIoU: 0.182\n__________________________\nEpoch: 24\n- Train Acc: 0.476\n- Train mIoU: 0.252\n\n- Test Acc: 0.337\n- Test Loss: 1.118\n- Test mIoU: 0.195\n__________________________\nEpoch: 25\n- Train Acc: 0.468\n- Train mIoU: 0.249\n\n- Test Acc: 0.327\n- Test Loss: 1.143\n- Test mIoU: 0.188\n__________________________\nEpoch: 26\n- Train Acc: 0.480\n- Train mIoU: 0.255\n\n- Test Acc: 0.338\n- Test Loss: 1.142\n- Test mIoU: 0.191\n__________________________\nEpoch: 27\n- Train Acc: 0.477\n- Train mIoU: 0.256\n\n- Test Acc: 0.324\n- Test Loss: 1.267\n- Test mIoU: 0.184\n__________________________\nEpoch: 28\n- Train Acc: 0.471\n- Train mIoU: 0.251\n\n- Test Acc: 0.327\n- Test Loss: 1.262\n- Test mIoU: 0.179\n__________________________\nEpoch: 29\n- Train Acc: 0.467\n- Train mIoU: 0.252\n\n- Test Acc: 0.322\n- Test Loss: 1.317\n- Test mIoU: 0.184\n__________________________\nEpoch: 30\n- Train Acc: 0.476\n- Train mIoU: 0.254\n\n- Test Acc: 0.325\n- Test Loss: 1.200\n- Test mIoU: 0.192\n__________________________\nEpoch: 31\n- Train Acc: 0.475\n- Train mIoU: 0.252\n\n- Test Acc: 0.318\n- Test Loss: 1.184\n- Test mIoU: 0.182\n__________________________\nEpoch: 32\n- Train Acc: 0.471\n- Train mIoU: 0.252\n\n- Test Acc: 0.302\n- Test Loss: 1.375\n- Test mIoU: 0.176\n__________________________\nEpoch: 33\n- Train Acc: 0.469\n- Train mIoU: 0.253\n\n- Test Acc: 0.327\n- Test Loss: 1.165\n- Test mIoU: 0.185\n__________________________\nEpoch: 34\n- Train Acc: 0.476\n- Train mIoU: 0.253\n\n- Test Acc: 0.308\n- Test Loss: 1.223\n- Test mIoU: 0.181\n__________________________\nEpoch: 35\n- Train Acc: 0.469\n- Train mIoU: 0.251\n\n- Test Acc: 0.321\n- Test Loss: 1.209\n- Test mIoU: 0.183\n__________________________\nEpoch: 36\n- Train Acc: 0.484\n- Train mIoU: 0.254\n\n- Test Acc: 0.317\n- Test Loss: 1.241\n- Test mIoU: 0.183\n__________________________\nEpoch: 37\n- Train Acc: 0.476\n- Train mIoU: 0.254\n\n- Test Acc: 0.317\n- Test Loss: 1.201\n- Test mIoU: 0.184\n__________________________\nEpoch: 38\n- Train Acc: 0.476\n- Train mIoU: 0.254\n\n- Test Acc: 0.317\n- Test Loss: 1.248\n- Test mIoU: 0.187\n__________________________\nEpoch: 39\n- Train Acc: 0.471\n- Train mIoU: 0.254\n\n- Test Acc: 0.337\n- Test Loss: 1.177\n- Test mIoU: 0.192\n__________________________\nEpoch: 40\n- Train Acc: 0.482\n- Train mIoU: 0.256\n\n- Test Acc: 0.326\n- Test Loss: 1.129\n- Test mIoU: 0.189\n__________________________\nEpoch: 41\n- Train Acc: 0.480\n- Train mIoU: 0.255\n\n- Test Acc: 0.324\n- Test Loss: 1.161\n- Test mIoU: 0.190\n__________________________\nEpoch: 42\n- Train Acc: 0.487\n- Train mIoU: 0.258\n\n- Test Acc: 0.331\n- Test Loss: 1.340\n- Test mIoU: 0.183\n__________________________\nEpoch: 43\n- Train Acc: 0.475\n- Train mIoU: 0.254\n\n- Test Acc: 0.333\n- Test Loss: 1.083\n- Test mIoU: 0.191\n__________________________\nEpoch: 44\n- Train Acc: 0.472\n- Train mIoU: 0.252\n\n- Test Acc: 0.322\n- Test Loss: 1.110\n- Test mIoU: 0.190\n__________________________\nEpoch: 45\n- Train Acc: 0.481\n- Train mIoU: 0.255\n\n- Test Acc: 0.334\n- Test Loss: 1.228\n- Test mIoU: 0.185\n__________________________\nEpoch: 46\n- Train Acc: 0.480\n- Train mIoU: 0.255\n\n- Test Acc: 0.307\n- Test Loss: 1.141\n- Test mIoU: 0.187\n__________________________\nEpoch: 47\n- Train Acc: 0.471\n- Train mIoU: 0.252\n\n- Test Acc: 0.323\n- Test Loss: 1.257\n- Test mIoU: 0.186\n__________________________\nEpoch: 48\n- Train Acc: 0.474\n- Train mIoU: 0.252\n\n- Test Acc: 0.333\n- Test Loss: 1.199\n- Test mIoU: 0.191\n__________________________\nEpoch: 49\n- Train Acc: 0.476\n- Train mIoU: 0.253\n\n- Test Acc: 0.340\n- Test Loss: 1.196\n- Test mIoU: 0.185\n__________________________\nEpoch: 50\n- Train Acc: 0.475\n- Train mIoU: 0.252\n\n- Test Acc: 0.309\n- Test Loss: 1.319\n- Test mIoU: 0.179\n__________________________\nEpoch: 51\n- Train Acc: 0.476\n- Train mIoU: 0.253\n\n- Test Acc: 0.329\n- Test Loss: 1.277\n- Test mIoU: 0.186\n- Iou per Class: 0.18643920187213014\n__________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: 1\n",
        "- Train Acc: 0.435\n",
        "- Train mIoU: 0.163\n",
        "\n",
        "- Test Acc: 0.297\n",
        "- Test Loss: 1.354\n",
        "- Test mIoU: 0.138\n",
        "- Iou per Class: 0.13785903419927545\n",
        "__________________________\n",
        "Epoch: 2\n",
        "- Train Acc: 0.459\n",
        "- Train mIoU: 0.210\n",
        "\n",
        "- Test Acc: 0.326\n",
        "- Test Loss: 1.303\n",
        "- Test mIoU: 0.154\n",
        "__________________________\n",
        "Epoch: 3\n",
        "- Train Acc: 0.471\n",
        "- Train mIoU: 0.227\n",
        "\n",
        "- Test Acc: 0.311\n",
        "- Test Loss: 1.347\n",
        "- Test mIoU: 0.160\n",
        "__________________________\n",
        "Epoch: 4\n",
        "- Train Acc: 0.470\n",
        "- Train mIoU: 0.234\n",
        "\n",
        "- Test Acc: 0.298\n",
        "- Test Loss: 1.414\n",
        "- Test mIoU: 0.166\n",
        "__________________________\n",
        "Epoch: 5\n",
        "- Train Acc: 0.472\n",
        "- Train mIoU: 0.240\n",
        "\n",
        "- Test Acc: 0.316\n",
        "- Test Loss: 1.255\n",
        "- Test mIoU: 0.172\n",
        "__________________________\n",
        "Epoch: 6\n",
        "- Train Acc: 0.467\n",
        "- Train mIoU: 0.242\n",
        "\n",
        "- Test Acc: 0.279\n",
        "- Test Loss: 1.842\n",
        "- Test mIoU: 0.136\n",
        "__________________________\n",
        "Epoch: 7\n",
        "- Train Acc: 0.462\n",
        "- Train mIoU: 0.242\n",
        "\n",
        "- Test Acc: 0.327\n",
        "- Test Loss: 1.180\n",
        "- Test mIoU: 0.174\n",
        "__________________________\n",
        "Epoch: 8\n",
        "- Train Acc: 0.471\n",
        "- Train mIoU: 0.248\n",
        "\n",
        "- Test Acc: 0.302\n",
        "- Test Loss: 1.414\n",
        "- Test mIoU: 0.174\n",
        "__________________________\n",
        "Epoch: 9\n",
        "- Train Acc: 0.467\n",
        "- Train mIoU: 0.249\n",
        "\n",
        "- Test Acc: 0.323\n",
        "- Test Loss: 1.102\n",
        "- Test mIoU: 0.186\n",
        "__________________________\n",
        "Epoch: 10\n",
        "- Train Acc: 0.470\n",
        "- Train mIoU: 0.255\n",
        "\n",
        "- Test Acc: 0.311\n",
        "- Test Loss: 1.249\n",
        "- Test mIoU: 0.178\n",
        "- Iou per Class: 0.17827379207672459"
      ],
      "metadata": {
        "id": "UU7oe8yBTC0i"
      }
    }
  ]
}