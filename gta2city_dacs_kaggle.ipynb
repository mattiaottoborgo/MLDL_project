{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8497954,
          "sourceType": "datasetVersion",
          "datasetId": 5070943
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "gta2city_dacs",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-23T16:04:36.143401Z",
          "iopub.execute_input": "2024-05-23T16:04:36.143787Z"
        },
        "id": "JniNLpXLhnq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#execute just the first time to move scripts and dataset from input to output\n",
        "import sys\n",
        "from shutil import copytree, copyfile\n",
        "sys.path.append(\"/kaggle/input/gta-dacs/\")\n",
        "\n",
        "src_datasets='/kaggle/input/gta-dacs/datasets'\n",
        "dst_datasets='/kaggle/working/datasets/'\n",
        "copytree(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/models'\n",
        "dst_datasets='/kaggle/working/models/'\n",
        "copytree(src_datasets, dst_datasets)\n",
        "#sys.path.append(\"/kaggle/input/cityscapes/\")\n",
        "\n",
        "# src_datasets='/kaggle/input/cityscapes/deeplab_resnet_pretrained_imagenet.pth'\n",
        "# dst_datasets='/kaggle/working/deeplab_resnet_pretrained_imagenet.pth'\n",
        "# copyfile(src_datasets, dst_datasets)\n",
        "\n",
        "src_datasets='/kaggle/input/gta-dacs/transformmasks.py'\n",
        "dst_datasets='/kaggle/working/transformmasks.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/transformsgpu.py'\n",
        "dst_datasets='/kaggle/working/transformgpu.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "\n",
        "\n",
        "copyfile(src = \"/kaggle/input/gta-dacs/utils.py\", dst = \"/kaggle/working/utils.py\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T19:18:04.82443Z",
          "iopub.execute_input": "2024-05-23T19:18:04.824844Z",
          "iopub.status.idle": "2024-05-23T19:18:07.222289Z",
          "shell.execute_reply.started": "2024-05-23T19:18:04.824813Z",
          "shell.execute_reply": "2024-05-23T19:18:07.221259Z"
        },
        "trusted": true,
        "id": "bPXEBAKthnq5",
        "outputId": "acfd8470-f92d-418c-f925-878474230c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/utils.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_datasets='/kaggle/input/gta-dacs/transformmasks.py'\n",
        "dst_datasets='/kaggle/working/transformmasks.py'\n",
        "copyfile(src_datasets, dst_datasets)\n",
        "src_datasets='/kaggle/input/gta-dacs/transformsgpu.py'\n",
        "dst_datasets='/kaggle/working/transformgpu.py'\n",
        "copyfile(src_datasets, dst_datasets)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T16:09:12.068676Z",
          "iopub.execute_input": "2024-05-23T16:09:12.069268Z",
          "iopub.status.idle": "2024-05-23T16:09:12.078488Z",
          "shell.execute_reply.started": "2024-05-23T16:09:12.069236Z",
          "shell.execute_reply": "2024-05-23T16:09:12.077749Z"
        },
        "trusted": true,
        "id": "G6z8-4IIhnq6",
        "outputId": "121df12c-f9e3-4542-f5a7-f02928790444"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/transformgpu.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.gta5 import GTA5\n",
        "from datasets.cityscapes import CityScapes\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import transformmasks\n",
        "import transformsgpu\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import posixpath\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from utils import poly_lr_scheduler\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "\n",
        "def strong_transform(parameters, data=None, target=None):\n",
        "    assert ((data is not None) or (target is not None))\n",
        "    data, target = transformsgpu.oneMix(mask=parameters[\"Mix\"], data=data, target=target)\n",
        "    data, target = transformsgpu.colorJitter(colorJitter=parameters[\"ColorJitter\"], img_mean=torch.from_numpy(IMG_MEAN.copy()).to(device), data=data, target=target)\n",
        "    data, target = transformsgpu.gaussian_blur(blur=parameters[\"GaussianBlur\"], data=data, target=target)\n",
        "    data, target = transformsgpu.flip(flip=parameters[\"flip\"], data=data, target=target)\n",
        "    return data, target\n",
        "\n",
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=19):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                #print(\"true class size\",true_class.shape)\n",
        "                #print(\"true label size\",true_label.shape)\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)\n",
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        correct = torch.eq(output, mask).int()\n",
        "        accuracy = float(correct.sum()) / float(correct.numel())\n",
        "    return accuracy\n",
        "\n",
        "def convert_tensor_to_image(tensor):\n",
        "    image = tensor.permute(1, 2, 0)\n",
        "    return image\n",
        "\n",
        "def train(model, optimizer, train_loader, target_loader, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    iou_score = 0.0\n",
        "    accuracy = 0.0\n",
        "    ii = 0\n",
        "\n",
        "    target_iter = iter(target_loader)\n",
        "    max_target_iter=250\n",
        "    target_counter=0\n",
        "    for batch_idx, source_batch in enumerate(train_loader):\n",
        "        if target_counter >= max_target_iter:\n",
        "            target_iter = iter(target_loader)\n",
        "            target_counter = 0\n",
        "        if ii % 100 == 0:\n",
        "            print(ii)\n",
        "        ii += 1\n",
        "\n",
        "        try:\n",
        "            target_batch = next(target_iter)\n",
        "        except StopIteration:\n",
        "            target_iter = iter(target_loader)\n",
        "            target_batch = next(target_iter)\n",
        "        target_counter+=1\n",
        "        inputs, targets = source_batch\n",
        "        target_inputs, _ = target_batch\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.squeeze()\n",
        "        target_inputs = target_inputs.to(device).float()\n",
        "\n",
        "        # Step 5: Generate pseudo-labels for target domain images\n",
        "        with torch.no_grad():\n",
        "            logits_u_w = model(target_inputs)[0]\n",
        "            pseudo_label = torch.softmax(logits_u_w, dim=1)\n",
        "            max_probs, targets_u_w = torch.max(pseudo_label, dim=1)\n",
        "\n",
        "        # Step 6: Create mixed images and pseudo-labels\n",
        "        batch_size = inputs.size(0)\n",
        "        MixMask = []\n",
        "        for image_i in range(batch_size):\n",
        "            classes = torch.unique(targets[image_i])\n",
        "            nclasses = classes.shape[0]\n",
        "            selected_classes = classes[torch.Tensor(np.random.choice(nclasses, int((nclasses + nclasses % 2) / 2), replace=False)).long()].to(device)\n",
        "            MixMask.append(transformmasks.generate_class_mask(targets[image_i], selected_classes).unsqueeze(0).to(device))\n",
        "\n",
        "        inputs_u_s_list, targets_u_s_list = [], []\n",
        "        for i, mask in enumerate(MixMask):\n",
        "            strong_parameters = {\"Mix\": mask, \"ColorJitter\": 0.2, \"GaussianBlur\": 0.5, \"flip\": 0.5}\n",
        "            inputs_u_s, targets_u_s = strong_transform(strong_parameters, data=torch.cat((inputs[i].unsqueeze(0), target_inputs[i].unsqueeze(0))), target=torch.cat((targets[i].unsqueeze(0), targets_u_w[i].unsqueeze(0))))\n",
        "            inputs_u_s_list.append(inputs_u_s)\n",
        "            targets_u_s_list.append(targets_u_s)\n",
        "\n",
        "        inputs_u_s = torch.cat(inputs_u_s_list)\n",
        "        targets_u_s = torch.cat(targets_u_s_list)\n",
        "\n",
        "        # Step 7: Compute predictions for mixed images\n",
        "        logits_u_s = model(inputs_u_s)[0]\n",
        "        L_u = F.cross_entropy(logits_u_s, targets_u_s, ignore_index=255, reduction='none')\n",
        "        mask = max_probs.ge(0.968).float()\n",
        "        L_u = (L_u * mask).mean()\n",
        "\n",
        "        # Compute predictions for source images\n",
        "        outputs, _, _ = model(inputs)\n",
        "        L_s = criterion(outputs.to(dtype=torch.float32), targets.to(dtype=torch.int64))\n",
        "\n",
        "        # Combine supervised and unsupervised losses\n",
        "        loss = L_s + L_u\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        iou_score += mIoU(outputs.to(device), targets.to(device))\n",
        "        accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    iou_score = iou_score / len(train_loader)\n",
        "    accuracy = accuracy / len(train_loader)\n",
        "    return train_loss, iou_score, accuracy\n",
        "# Test loop\n",
        "# calculate_label_prediction is a flag used to decide wether to calculate or not ground_truth and predicted tensor\n",
        "def test(model, test_loader, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    iou_score=0.0\n",
        "    accuracy=0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx,(inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            inputs = inputs.float()\n",
        "            targets = targets.int()\n",
        "            #Compute prediction and loss\n",
        "            outputs = model(inputs)\n",
        "            #print(batch_idx)\n",
        "            loss = loss_fn(outputs.to(dtype=torch.float32), targets.squeeze().to(dtype=torch.int64))\n",
        "            iou_score += mIoU(outputs.to(device), targets.to(device))\n",
        "            accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
        "            test_loss += loss.item()\n",
        "            #break\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    iou_score = iou_score / len(test_loader)\n",
        "    accuracy = accuracy / len(test_loader)\n",
        "    #test_accuracy = 100. * correct / total\n",
        "    return test_loss,iou_score,accuracy\n",
        "\n",
        "print(CityScapes)\n",
        "#dataset_path='/kaggle/input/cityscapes-polito/Cityscapes/Cityscapes/Cityspaces/'\n",
        "gta_dataset_path='/kaggle/input/gta-dacs/GTA5/GTA5/GTA5/'\n",
        "annotation_train=gta_dataset_path+'labels_correct/'\n",
        "image_train=gta_dataset_path+'images/'\n",
        "cityscapes_dataset_path='/kaggle/input/gta-dacs/Cityscapes/Cityscapes/Cityspaces/'\n",
        "annotation_val=cityscapes_dataset_path+'gtFine/val'\n",
        "image_val=cityscapes_dataset_path+'images/val'\n",
        "annotation_val_train=cityscapes_dataset_path+'gtFine/train'\n",
        "image_val_train=cityscapes_dataset_path+'images/train'\n",
        "resize_transform_gta = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (720,1280))\n",
        "resize_transform = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (512,1024))\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "applier_crop = v2.RandomApply(transforms=[v2.RandomCrop(size=(512, 1024))], p=0.5)\n",
        "gta_train = GTA5(annotations_dir=annotation_train, images_dir=image_train,transform=resize_transform,applier=applier_crop)\n",
        "cityscapes_val = CityScapes(annotations_dir=annotation_val, images_dir=image_val,transform=resize_transform,applier=applier_crop)\n",
        "cityscapes_train=CityScapes(annotations_dir=annotation_val_train, images_dir=image_val_train,transform=resize_transform,applier=applier_crop)\n",
        "train_loader = DataLoader(gta_train, batch_size=2, shuffle=False)\n",
        "val_loader = DataLoader(cityscapes_val, batch_size=2, shuffle=False)\n",
        "train_loader_cityscapes= DataLoader(cityscapes_train, batch_size=2, shuffle=False)\n",
        "# Define the model and load it to the device\n",
        "bisenet = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "bisenet.to(device)\n",
        "optimizer = torch.optim.Adam(bisenet.parameters(), lr=0.001)\n",
        "scheduler=poly_lr_scheduler(optimizer, 0.01, 1, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "epoch_beginning=0\n",
        "epochs = 50"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T20:02:04.851785Z",
          "iopub.execute_input": "2024-05-23T20:02:04.852188Z",
          "iopub.status.idle": "2024-05-23T20:02:21.11722Z",
          "shell.execute_reply.started": "2024-05-23T20:02:04.852146Z",
          "shell.execute_reply": "2024-05-23T20:02:21.116051Z"
        },
        "trusted": true,
        "id": "09lsVF0Hhnq6",
        "outputId": "90eee5a0-8caa-41e6-8163-3a1cd8739d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'datasets.cityscapes.CityScapes'>\ncuda\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_cityscapes.dataset.__len__()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T20:02:25.540773Z",
          "iopub.execute_input": "2024-05-23T20:02:25.541165Z",
          "iopub.status.idle": "2024-05-23T20:02:25.548047Z",
          "shell.execute_reply.started": "2024-05-23T20:02:25.541133Z",
          "shell.execute_reply": "2024-05-23T20:02:25.546988Z"
        },
        "trusted": true,
        "id": "pw8wbcgvhnq7",
        "outputId": "971884b3-01c5-4250-80cc-5449c79ea729"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1572"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model and load it to the device\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model.to(device)\n",
        "epoch = 0 #to initialize the lr\n",
        "start_lr = 1e-2\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
        "l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T20:02:26.997342Z",
          "iopub.execute_input": "2024-05-23T20:02:26.997765Z",
          "iopub.status.idle": "2024-05-23T20:02:28.27808Z",
          "shell.execute_reply.started": "2024-05-23T20:02:26.997714Z",
          "shell.execute_reply": "2024-05-23T20:02:28.27697Z"
        },
        "trusted": true,
        "id": "dLJSb9pwhnq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D72f7nyThnq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze model parameters, but in avery fancy way\n",
        "for index,param in enumerate(model.parameters()):\n",
        "    if index < 75:\n",
        "        param.requires_grad=False\n",
        "#         print(index)\n",
        "for param in model.attention_refinement_module2.parameters():\n",
        "    param.requires_grad=False\n",
        "for param in model.feature_fusion_module.parameters():\n",
        "    param.requires_grad=True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T20:02:28.886738Z",
          "iopub.execute_input": "2024-05-23T20:02:28.887115Z",
          "iopub.status.idle": "2024-05-23T20:02:28.894983Z",
          "shell.execute_reply.started": "2024-05-23T20:02:28.887084Z",
          "shell.execute_reply": "2024-05-23T20:02:28.893637Z"
        },
        "trusted": true,
        "id": "eWXLfVFNhnq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iou_list=[]\n",
        "train_acc_list=[]\n",
        "train_loss_list=[]\n",
        "test_iou_list=[]\n",
        "class_iou_list=[]\n",
        "test_acc_list=[]\n",
        "test_loss_list=[]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T20:02:30.571375Z",
          "iopub.execute_input": "2024-05-23T20:02:30.5718Z",
          "iopub.status.idle": "2024-05-23T20:02:30.577343Z",
          "shell.execute_reply.started": "2024-05-23T20:02:30.571769Z",
          "shell.execute_reply": "2024-05-23T20:02:30.576226Z"
        },
        "trusted": true,
        "id": "7n1w0iBzhnq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "bs=2\n",
        "epoch_beginning = 0\n",
        "epochs = 10\n",
        "for epoch in range(epoch_beginning,epochs):\n",
        "    n_epoch = epoch+1\n",
        "    l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
        "    #train\n",
        "    train_loss,train_iou,train_acc=train(model, optimizer, train_loader,train_loader_cityscapes, loss_fn)\n",
        "    train_iou = np.nanmean(train_iou)\n",
        "    train_iou_list.append(train_iou)\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    #save model\n",
        "    if n_epoch%5 == 0 or n_epoch==epochs:\n",
        "        model_name = f\"bisenet_GTA5_bs{bs}_epoch{n_epoch}_weights.pth\"\n",
        "        torch.save(model.state_dict(), model_name)\n",
        "\n",
        "    #test\n",
        "    test_loss,class_iou,test_acc = test(model, val_loader, loss_fn)\n",
        "    test_iou = np.nanmean(class_iou)\n",
        "    test_iou_list.append(test_iou)\n",
        "    class_iou_list.append(class_iou)\n",
        "    test_acc_list.append(test_acc)\n",
        "    test_loss_list.append(test_loss)\n",
        "\n",
        "    f = open(\"train_iou_list.txt\", \"a\")\n",
        "    f.write(str(train_iou)+ \"\\n\")\n",
        "    f.close()\n",
        "    f = open(\"test_iou_list.txt\", \"a\")\n",
        "    f.write(str(test_iou)+ \"\\n\")\n",
        "    f.close()\n",
        "\n",
        "    print(f\"Epoch: {n_epoch}\")\n",
        "    print(f\"- Train Acc: {train_acc:.3f}\")\n",
        "#     print(f\"- Train Loss: {test_loss:.3f}\")\n",
        "    print(f\"- Train mIoU: {train_iou:.3f}\\n\")\n",
        "    print(f\"- Test Acc: {test_acc:.3f}\")\n",
        "    print(f\"- Test Loss: {test_loss:.3f}\")\n",
        "    print(f\"- Test mIoU: {test_iou:.3f}\")\n",
        "    if n_epoch==1 or n_epoch == epochs:\n",
        "        print(f\"- Iou per Class: {class_iou}\")\n",
        "    print(\"__________________________\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T22:12:00.513461Z",
          "iopub.execute_input": "2024-05-23T22:12:00.514342Z",
          "iopub.status.idle": "2024-05-23T22:12:00.526439Z",
          "shell.execute_reply.started": "2024-05-23T22:12:00.514304Z",
          "shell.execute_reply": "2024-05-23T22:12:00.525231Z"
        },
        "trusted": true,
        "id": "QM6QwFlYhnq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: 1\n",
        "- Train Acc: 0.435\n",
        "- Train mIoU: 0.163\n",
        "\n",
        "- Test Acc: 0.297\n",
        "- Test Loss: 1.354\n",
        "- Test mIoU: 0.138\n",
        "- Iou per Class: 0.13785903419927545\n",
        "__________________________\n",
        "Epoch: 2\n",
        "- Train Acc: 0.459\n",
        "- Train mIoU: 0.210\n",
        "\n",
        "- Test Acc: 0.326\n",
        "- Test Loss: 1.303\n",
        "- Test mIoU: 0.154\n",
        "__________________________\n",
        "Epoch: 3\n",
        "- Train Acc: 0.471\n",
        "- Train mIoU: 0.227\n",
        "\n",
        "- Test Acc: 0.311\n",
        "- Test Loss: 1.347\n",
        "- Test mIoU: 0.160\n",
        "__________________________\n",
        "Epoch: 4\n",
        "- Train Acc: 0.470\n",
        "- Train mIoU: 0.234\n",
        "\n",
        "- Test Acc: 0.298\n",
        "- Test Loss: 1.414\n",
        "- Test mIoU: 0.166\n",
        "__________________________\n",
        "Epoch: 5\n",
        "- Train Acc: 0.472\n",
        "- Train mIoU: 0.240\n",
        "\n",
        "- Test Acc: 0.316\n",
        "- Test Loss: 1.255\n",
        "- Test mIoU: 0.172\n",
        "__________________________\n",
        "Epoch: 6\n",
        "- Train Acc: 0.467\n",
        "- Train mIoU: 0.242\n",
        "\n",
        "- Test Acc: 0.279\n",
        "- Test Loss: 1.842\n",
        "- Test mIoU: 0.136\n",
        "__________________________\n",
        "Epoch: 7\n",
        "- Train Acc: 0.462\n",
        "- Train mIoU: 0.242\n",
        "\n",
        "- Test Acc: 0.327\n",
        "- Test Loss: 1.180\n",
        "- Test mIoU: 0.174\n",
        "__________________________\n",
        "Epoch: 8\n",
        "- Train Acc: 0.471\n",
        "- Train mIoU: 0.248\n",
        "\n",
        "- Test Acc: 0.302\n",
        "- Test Loss: 1.414\n",
        "- Test mIoU: 0.174\n",
        "__________________________\n",
        "Epoch: 9\n",
        "- Train Acc: 0.467\n",
        "- Train mIoU: 0.249\n",
        "\n",
        "- Test Acc: 0.323\n",
        "- Test Loss: 1.102\n",
        "- Test mIoU: 0.186\n",
        "__________________________\n",
        "Epoch: 10\n",
        "- Train Acc: 0.470\n",
        "- Train mIoU: 0.255\n",
        "\n",
        "- Test Acc: 0.311\n",
        "- Test Loss: 1.249\n",
        "- Test mIoU: 0.178\n",
        "- Iou per Class: 0.17827379207672459"
      ],
      "metadata": {
        "id": "0qNximKThnq-"
      }
    }
  ]
}