{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#execute just the first time to move scripts and dataset from input to output\nimport sys\nfrom shutil import copytree, copyfile\nsys.path.append( \"/kaggle/input/cityscapes\" )\n\nsrc_datasets='/kaggle/input/cityscapes/datasets/'\ndst_datasets='/kaggle/working/datasets/'\ncopytree(src_datasets, dst_datasets)\n\nsrc_datasets='/kaggle/input/cityscapes/Cityscapes_v2.py'\ndst_datasets='/kaggle/working/datasets/Cityscapes_v2.py'\ncopyfile(src_datasets, dst_datasets)\n\nsrc_datasets='/kaggle/input/cityscapes/deeplab_resnet_pretrained_imagenet.pth'\ndst_datasets='/kaggle/working/deeplab_resnet_pretrained_imagenet.pth'\ncopyfile(src_datasets, dst_datasets)\n\nsrc_models='/kaggle/input/cityscapes/models'\ndst_models='/kaggle/working/models/'\ncopytree(src_models, dst_models)\n\ncopyfile(src = \"/kaggle/input/cityscapes/utils.py\", dst = \"/kaggle/working/utils.py\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this one you need it always\nsys.path.append('/kaggle/input/cityscapes/datasets/') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO: Define here your training and validation loops.\n\nimport torch.nn.functional as F\nfrom Cityscapes import CityScapes\nfrom torch.utils.data import DataLoader\nimport torch\nimport numpy as np\nfrom torchvision import transforms\nfrom torchvision.transforms import v2\nimport matplotlib.pyplot as plt\nfrom models.bisenet.build_bisenet import BiSeNet\nfrom utils import poly_lr_scheduler\n\ndef mIoU(pred_mask, mask, smooth=1e-10, n_classes=19):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n\n        iou_per_class = []\n        for clas in range(0, n_classes): #loop per pixel class\n            true_class = pred_mask == clas\n            true_label = mask == clas\n\n            if true_label.long().sum().item() == 0: #no exist label in this loop\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n                union = torch.logical_or(true_class, true_label).sum().float().item()\n\n                iou = (intersect + smooth) / (union + smooth)\n                iou_per_class.append(iou)\n        return np.nanmean(iou_per_class), iou_per_class\n    \ndef pixel_accuracy(output, mask):\n    with torch.no_grad():\n        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n        correct = torch.eq(output, mask).int()\n        accuracy = float(correct.sum()) / float(correct.numel())\n    return accuracy\n\ndef convert_tensor_to_image(tensor):\n    image = tensor.permute(1, 2, 0)\n    return image\n\ndef train(model, optimizer, train_loader, criterion):\n    model.train()\n    running_loss = 0.0\n    total = 0\n    iou_score=0\n    accuracy=0\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        inputs = inputs.float()\n        targets = targets.squeeze(dim=1)\n        \n        #Compute prediction and loss\n        outputs,_,_ = model(inputs)\n        loss = loss_fn(outputs.to(dtype=torch.float32), targets.to(dtype=torch.int64))\n        iou_score += mIoU(outputs.to(device), targets.to(device))\n        accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n        \n        #BackPropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    \n    train_loss = running_loss / len(train_loader)\n    iou_score = iou_score / len(train_loader)\n    accuracy = accuracy / len(train_loader)\n    return train_loss,iou_score,accuracy\n\n# Test loop\ndef test(model, test_loader, loss_fn):\n    model.eval()\n    test_loss = 0\n    iou_score=0.0\n    accuracy=0.0\n    with torch.no_grad():\n        for batch_idx,(inputs, targets) in enumerate(test_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            inputs = inputs.float()\n            targets = targets.int()\n            \n            #Compute prediction and loss\n            outputs = model(inputs)\n            loss = loss_fn(outputs.to(dtype=torch.float32), targets.squeeze(dim=1).to(dtype=torch.int64))\n            iou_score += mIoU(outputs.to(device), targets.to(device))\n            accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n            test_loss += loss.item()\n            \n    test_loss = test_loss / len(test_loader)\n    iou_score = iou_score / len(test_loader)\n    accuracy = accuracy / len(test_loader)\n    #test_accuracy = 100. * correct / total\n    return test_loss,iou_score,accuracy\n\ngta_path = '/kaggle/input/GTA/GTA5/GTA5/'\nimage_train = gta_dataset_path+'images/'\nsem_map_train = gta_dataset_path+'labels_correct/'\ncityscapes_path = '/kaggle/input/cityscapes/Cityscapes/Cityscapes/Cityspaces/'\nimage_val = dataset_path+'images/val'\nsem_map_val = dataset_path+'gtFine/val'\n\nresize_transform_gta = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (720,1280))\nresize_transform = transforms.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (512,1024))\n\n# Setup device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply data augmentation\n# applier_crop = v2.RandomApply(transforms=[v2.RandomCrop(size=(512, 1024))], p=0.5)\n\n# Define Datasets and Dataloaders\ngta_train = GTA5(annotations_dir=sem_map_train, images_dir=image_train,transform=resize_transform_gta)\ncityscapes_val = CityScapes(annotations_dir=sem_map_val, images_dir=image_val,transform=resize_transform)\n\nbs = 5\ntrain_loader = DataLoader(gta_train, batch_size=bs, shuffle=False)\nval_loader = DataLoader(cityscapes_val, batch_size=bs, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'training dataset contains {cityscapes_train.__len__()} images')\nprint(f'validation dataset contains {cityscapes_val.__len__()} images')\n\nindex = 564\n# print('Image path: \\n'f'{cityscapes_train.map_index_to_image[index]}')\n# print('Map path: \\n'f'{cityscapes_train.map_index_to_annotation[index]}')\nimage, sem_map = cityscapes_train.__getitem__(index)\nsem_map.size()\nfig, axes = plt.subplots(2, 1)\nimage_transpose = convert_tensor_to_image(image)\nmap_transpose = convert_tensor_to_image(sem_map)\naxes[0].imshow(image_transpose)\naxes[1].imshow(map_transpose, cmap='Blues')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model and load it to the device\nmodel = BiSeNet(num_classes=19, context_path='resnet18')\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler=poly_lr_scheduler(optimizer, 0.01, 1, lr_decay_iter=1, max_iter=50, power=0.9)\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\nsummary(model, input_size=(bs,3,720,1280), col_names=[\"num_params\", \"trainable\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_iou_list=[]\ntrain_acc_list=[]\ntrain_loss_list=[]\ntest_iou_list=[]\ntest_acc_list=[]\ntest_loss_list=[]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n\nepoch_beginning=1\nepochs = 50+epoch_beginning\n\nfor epoch in range(epoch_beginning,epochs):\n    train_loss,train_iou,train_acc=train(model, optimizer, train_loader, loss_fn)\n    train_iou_list.append(train_iou)\n    train_acc_list.append(train_acc)\n    train_loss_list.append(train_loss)\n    \n    #save model\n    if epoch%5 == 0 or epoch==epochs:\n        model_name = f\"bisenet_GTA5_bs{bs}_epoch{epoch}_weights.pth\"\n        torch.save(model.state_dict(), model_name)\n        \n    #test    \n    test_loss,test_iou,test_acc = test(model, val_loader, loss_fn)\n    test_iou_list.append(test_iou)\n    test_acc_list.append(test_acc)\n    test_loss_list.append(test_loss)\n    \n    f = open(\"train_iou_list.txt\", \"a\")\n    f.write(str(train_iou)+ \"\\n\")\n    f.close()\n    f = open(\"test_iou_list.txt\", \"a\")\n    f.write(str(test_iou)+ \"\\n\")\n    f.close()\n    \n    print(f\"Epoch: {epoch}\")\n    print(f\"- Train Acc: {test_acc:.3f}\")\n#     print(f\"- Train Loss: {test_loss:.3f}\")\n    print(f\"- Train mIoU: {test_iou:.3f}\\n\")\n    print(f\"- Test Acc: {test_acc:.3f}\")\n#     print(f\"- Test Loss: {test_loss:.3f}\")\n    print(f\"- Test mIoU: {test_iou:.3f}\")\n    print(\"__________________________\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Graphs\nmetrics = np.stack(arrays=[train_iou_list ,train_acc_list , train_loss_list, test_iou_list, test_acc_list, test_loss_list], axis=0)\n\nnames = [\"mIou\", \"Accuracy\", \"Loss\"]\nplotted = 0\nplt.figure(figsize=(15,3))\nfor i in range(len(names)):\n    plotted += 1\n    plt.subplot(1,3,plotted) \n    plt.plot(range(1, 12), metrics[i], label=\"Train\")\n    plt.plot(range(1, 12), metrics[i+len(names)], label=\"Test\")\n    plt.title(f\"{names[i]}\")\n    plt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FLOPS\nfrom fvcore.nn import FlopCountAnalysis, flop_count_table\n\nplot_loader = DataLoader(cityscapes_train, batch_size=1, shuffle=True)\n(input,output) = next(iter(plot_loader))\nheight = 512\nwidth = 1024\n\nflops = FlopCountAnalysis(model, input.to(device,dtype=torch.float32))\nprint(flop_count_table(flops))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Latency and FPS\nimport time \nimport numpy as np\nnet = model\nnet.eval()\nfps_loader = DataLoader(cityscapes_train, batch_size=1, shuffle=True)\n(inputs, annotations) = next(iter(fps_loader))\ninputs=inputs.to(device,dtype=torch.float32)\niterations=1000\nlatency=np.empty(0)\nFPS=np.empty(0)\nfor i in range(iterations):\n    start=time.time()\n    output=net(inputs)\n    end=time.time()\n    latency_i=end-start\n    #print(latency_i)\n    latency=np.append(latency,latency_i)\n    FPS_i=float(1/latency_i)\n    FPS=np.append(FPS,FPS_i)\nmeanLatency=np.mean(latency)\nstdLatency=np.std(latency)\nmeanFPS=np.mean(FPS)\nstdFPS=np.std(FPS)\n\nprint (f\"mean latency: {meanLatency} seconds\")\nprint(f\"std latency: {stdLatency} seconds\")\nprint (f\"mean FPS: {meanFPS} fps\")\nprint(f\"std FPS: {stdFPS} fps\")","metadata":{},"execution_count":null,"outputs":[]}]}