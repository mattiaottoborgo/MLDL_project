{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TVTensors FAQ\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Try on [collab](https://colab.research.google.com/github/pytorch/vision/blob/gh-pages/main/_generated_ipynb_notebooks/plot_tv_tensors.ipynb)\n",
    "    or `go to the end <sphx_glr_download_auto_examples_transforms_plot_tv_tensors.py>` to download the full example code.</p></div>\n",
    "\n",
    "\n",
    "TVTensors are Tensor subclasses introduced together with\n",
    "``torchvision.transforms.v2``. This example showcases what these TVTensors are\n",
    "and how they behave.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>**Intended Audience** Unless you're writing your own transforms or your own TVTensors, you\n",
    "    probably do not need to read this guide. This is a fairly low-level topic\n",
    "    that most users will not need to worry about: you do not need to understand\n",
    "    the internals of TVTensors to efficiently rely on\n",
    "    ``torchvision.transforms.v2``. It may however be useful for advanced users\n",
    "    trying to implement their own datasets, transforms, or work directly with\n",
    "    the TVTensors.</p></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "import torch\n",
    "from torchvision import tv_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are TVTensors?\n",
    "\n",
    "TVTensors are zero-copy tensor subclasses:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 256, 256)\n",
    "image = tv_tensors.Image(tensor)\n",
    "\n",
    "assert isinstance(image, torch.Tensor)\n",
    "assert image.data_ptr() == tensor.data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, they are needed in :mod:`torchvision.transforms.v2` to correctly dispatch to the appropriate function\n",
    "for the input data.\n",
    "\n",
    ":mod:`torchvision.tv_tensors` supports four types of TVTensors:\n",
    "\n",
    "* :class:`~torchvision.tv_tensors.Image`\n",
    "* :class:`~torchvision.tv_tensors.Video`\n",
    "* :class:`~torchvision.tv_tensors.BoundingBoxes`\n",
    "* :class:`~torchvision.tv_tensors.Mask`\n",
    "\n",
    "## What can I do with a TVTensor?\n",
    "\n",
    "TVTensors look and feel just like regular tensors - they **are** tensors.\n",
    "Everything that is supported on a plain :class:`torch.Tensor` like ``.sum()`` or\n",
    "any ``torch.*`` operator will also work on TVTensors. See\n",
    "`tv_tensor_unwrapping_behaviour` for a few gotchas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How do I construct a TVTensor?\n",
    "\n",
    "### Using the constructor\n",
    "\n",
    "Each TVTensor class takes any tensor-like data that can be turned into a :class:`~torch.Tensor`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image = tv_tensors.Image([[[[0, 1], [1, 0]]]])\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to other PyTorch creations ops, the constructor also takes the ``dtype``, ``device``, and ``requires_grad``\n",
    "parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "float_image = tv_tensors.Image([[[0, 1], [1, 0]]], dtype=torch.float32, requires_grad=True)\n",
    "print(float_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, :class:`~torchvision.tv_tensors.Image` and :class:`~torchvision.tv_tensors.Mask` can also take a\n",
    ":class:`PIL.Image.Image` directly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image = tv_tensors.Image(PIL.Image.open(\"../assets/astronaut.jpg\"))\n",
    "print(image.shape, image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some TVTensors require additional metadata to be passed in ordered to be constructed. For example,\n",
    ":class:`~torchvision.tv_tensors.BoundingBoxes` requires the coordinate format as well as the size of the\n",
    "corresponding image (``canvas_size``) alongside the actual values. These\n",
    "metadata are required to properly transform the bounding boxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bboxes = tv_tensors.BoundingBoxes(\n",
    "    [[17, 16, 344, 495], [0, 10, 0, 10]],\n",
    "    format=tv_tensors.BoundingBoxFormat.XYXY,\n",
    "    canvas_size=image.shape[-2:]\n",
    ")\n",
    "print(bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ``tv_tensors.wrap()``\n",
    "\n",
    "You can also use the :func:`~torchvision.tv_tensors.wrap` function to wrap a tensor object\n",
    "into a TVTensor. This is useful when you already have an object of the\n",
    "desired type, which typically happens when writing transforms: you just want\n",
    "to wrap the output like the input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_bboxes = torch.tensor([0, 20, 30, 40])\n",
    "new_bboxes = tv_tensors.wrap(new_bboxes, like=bboxes)\n",
    "assert isinstance(new_bboxes, tv_tensors.BoundingBoxes)\n",
    "assert new_bboxes.canvas_size == bboxes.canvas_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata of ``new_bboxes`` is the same as ``bboxes``, but you could pass\n",
    "it as a parameter to override it.\n",
    "\n",
    "\n",
    "## I had a TVTensor but now I have a Tensor. Help!\n",
    "\n",
    "By default, operations on :class:`~torchvision.tv_tensors.TVTensor` objects\n",
    "will return a pure Tensor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(bboxes, tv_tensors.BoundingBoxes)\n",
    "\n",
    "# Shift bboxes by 3 pixels in both H and W\n",
    "new_bboxes = bboxes + 3\n",
    "\n",
    "assert isinstance(new_bboxes, torch.Tensor)\n",
    "assert not isinstance(new_bboxes, tv_tensors.BoundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>This behavior only affects native ``torch`` operations. If you are using\n",
    "   the built-in ``torchvision`` transforms or functionals, you will always get\n",
    "   as output the same type that you passed as input (pure ``Tensor`` or\n",
    "   ``TVTensor``).</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But I want a TVTensor back!\n",
    "\n",
    "You can re-wrap a pure tensor into a TVTensor by just calling the TVTensor\n",
    "constructor, or by using the :func:`~torchvision.tv_tensors.wrap` function\n",
    "(see more details above in `tv_tensor_creation`):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_bboxes = bboxes + 3\n",
    "new_bboxes = tv_tensors.wrap(new_bboxes, like=bboxes)\n",
    "assert isinstance(new_bboxes, tv_tensors.BoundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the :func:`~torchvision.tv_tensors.set_return_type`\n",
    "as a global config setting for the whole program, or as a context manager\n",
    "(read its docs to learn more about caveats):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with tv_tensors.set_return_type(\"TVTensor\"):\n",
    "    new_bboxes = bboxes + 3\n",
    "assert isinstance(new_bboxes, tv_tensors.BoundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this happening?\n",
    "\n",
    "**For performance reasons**. :class:`~torchvision.tv_tensors.TVTensor`\n",
    "classes are Tensor subclasses, so any operation involving a\n",
    ":class:`~torchvision.tv_tensors.TVTensor` object will go through the\n",
    "[__torch_function__](https://pytorch.org/docs/stable/notes/extending.html#extending-torch)\n",
    "protocol. This induces a small overhead, which we want to avoid when possible.\n",
    "This doesn't matter for built-in ``torchvision`` transforms because we can\n",
    "avoid the overhead there, but it could be a problem in your model's\n",
    "``forward``.\n",
    "\n",
    "**The alternative isn't much better anyway.** For every operation where\n",
    "preserving the :class:`~torchvision.tv_tensors.TVTensor` type makes\n",
    "sense, there are just as many operations where returning a pure Tensor is\n",
    "preferable: for example, is ``img.sum()`` still an :class:`~torchvision.tv_tensors.Image`?\n",
    "If we were to preserve :class:`~torchvision.tv_tensors.TVTensor` types all\n",
    "the way, even model's logits or the output of the loss function would end up\n",
    "being of type :class:`~torchvision.tv_tensors.Image`, and surely that's not\n",
    "desirable.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>This behaviour is something we're actively seeking feedback on. If you find this surprising or if you\n",
    "   have any suggestions on how to better support your use-cases, please reach out to us via this issue:\n",
    "   https://github.com/pytorch/vision/issues/7319</p></div>\n",
    "\n",
    "### Exceptions\n",
    "\n",
    "There are a few exceptions to this \"unwrapping\" rule:\n",
    ":meth:`~torch.Tensor.clone`, :meth:`~torch.Tensor.to`,\n",
    ":meth:`torch.Tensor.detach`, and :meth:`~torch.Tensor.requires_grad_` retain\n",
    "the TVTensor type.\n",
    "\n",
    "Inplace operations on TVTensors like ``obj.add_()`` will preserve the type of\n",
    "``obj``. However, the **returned** value of inplace operations will be a pure\n",
    "tensor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image = tv_tensors.Image([[[0, 1], [1, 0]]])\n",
    "\n",
    "new_image = image.add_(1).mul_(2)\n",
    "\n",
    "# image got transformed in-place and is still a TVTensor Image, but new_image\n",
    "# is a Tensor. They share the same underlying data and they're equal, just\n",
    "# different classes.\n",
    "assert isinstance(image, tv_tensors.Image)\n",
    "print(image)\n",
    "\n",
    "assert isinstance(new_image, torch.Tensor) and not isinstance(new_image, tv_tensors.Image)\n",
    "assert (new_image == image).all()\n",
    "assert new_image.data_ptr() == image.data_ptr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
