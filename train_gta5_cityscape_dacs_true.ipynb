{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.cityscapes.CityScapes'>\n"
     ]
    }
   ],
   "source": [
    "from datasets.gta5 import GTA5\n",
    "from datasets.cityscapes import CityScapes\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import posixpath\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from utils import poly_lr_scheduler\n",
    "\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=19):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                #print(\"true class size\",true_class.shape)\n",
    "                #print(\"true label size\",true_label.shape)\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)\n",
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy\n",
    "\n",
    "def convert_tensor_to_image(tensor):\n",
    "    image = tensor.permute(1, 2, 0)\n",
    "    return image\n",
    "def train(model,optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    iou_score=0.0\n",
    "    accuracy=0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        print(\"Batch: \", batch_idx)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs.float()\n",
    "        targets = targets.squeeze()\n",
    "        #Compute prediction and loss\n",
    "        outputs,_,_ = model(inputs)\n",
    "        print(batch_idx)\n",
    "        \n",
    "        loss = loss_fn(outputs.to(dtype=torch.float32), targets.to(dtype=torch.int64))\n",
    "        iou_score += mIoU(outputs.to(device), targets.to(device))\n",
    "        accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
    "        #BackPropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "    before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step()\n",
    "    after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    iou_score = iou_score / len(train_loader)\n",
    "    accuracy = accuracy / len(train_loader)\n",
    "    return train_loss,iou_score,accuracy\n",
    "\n",
    "# Test loop\n",
    "# calculate_label_prediction is a flag used to decide wether to calculate or not ground_truth and predicted tensor\n",
    "def test(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    iou_score=0.0\n",
    "    accuracy=0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.float()\n",
    "            targets = targets.int()\n",
    "            #Compute prediction and loss\n",
    "            outputs = model(inputs)\n",
    "            print(batch_idx)\n",
    "            loss = loss_fn(outputs.to(dtype=torch.float32), targets.squeeze().to(dtype=torch.int64))\n",
    "            iou_score += mIoU(outputs.to(device), targets.to(device))\n",
    "            accuracy += pixel_accuracy(outputs.to(device), targets.to(device))\n",
    "            test_loss += loss.item()\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    iou_score = iou_score / len(test_loader)\n",
    "    accuracy = accuracy / len(test_loader)\n",
    "    #test_accuracy = 100. * correct / total\n",
    "    return test_loss,iou_score,accuracy\n",
    "\n",
    "print(CityScapes)\n",
    "#dataset_path='/kaggle/input/cityscapes-polito/Cityscapes/Cityscapes/Cityspaces/'\n",
    "gta_dataset_path='GTA5/GTA5/'\n",
    "annotation_train=gta_dataset_path+'labels_correct/'\n",
    "image_train=gta_dataset_path+'images/'\n",
    "cityscapes_dataset_path='Cityscapes/Cityscapes/Cityspaces/'\n",
    "annotation_val=cityscapes_dataset_path+'gtFine/val'\n",
    "image_val=cityscapes_dataset_path+'images/val'\n",
    "resize_transform_gta = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (720,1280))\n",
    "resize_transform = v2.Resize(interpolation=transforms.InterpolationMode.NEAREST_EXACT,size = (512,1024))\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "applier_crop = v2.RandomApply(transforms=[v2.RandomCrop(size=(512, 1024))], p=0.5)\n",
    "gta_train = GTA5(annotations_dir=annotation_train, images_dir=image_train,transform=resize_transform,applier=applier_crop)\n",
    "cityscapes_val = CityScapes(annotations_dir=annotation_val, images_dir=image_val,transform=resize_transform,applier=applier_crop)\n",
    "\n",
    "train_loader = DataLoader(gta_train, batch_size=2, shuffle=False)\n",
    "val_loader = DataLoader(cityscapes_val, batch_size=2, shuffle=False)\n",
    "\n",
    "# Define the model and load it to the device\n",
    "bisenet = BiSeNet(num_classes=19, context_path='resnet18')\n",
    "bisenet.to(device)\n",
    "optimizer = torch.optim.Adam(bisenet.parameters(), lr=0.001)\n",
    "scheduler=poly_lr_scheduler(optimizer, 0.01, 1, lr_decay_iter=1, max_iter=50, power=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "epoch_beginning=0\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and load it to the device\n",
    "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
    "model.to(device)\n",
    "epoch = 0 #to initialize the lr\n",
    "start_lr = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
    "l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze model parameters, but in avery fancy way\n",
    "for index,param in enumerate(model.parameters()):\n",
    "    if index < 75:\n",
    "        param.requires_grad=False\n",
    "#         print(index)\n",
    "for param in model.attention_refinement_module2.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in model.feature_fusion_module.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iou_list=[]\n",
    "train_acc_list=[]\n",
    "train_loss_list=[]\n",
    "test_iou_list=[]\n",
    "class_iou_list=[]\n",
    "test_acc_list=[]\n",
    "test_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciaoo\n",
      "Batch:  0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m l_rate \u001b[38;5;241m=\u001b[39m poly_lr_scheduler(optimizer, init_lr\u001b[38;5;241m=\u001b[39mstart_lr , \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39mepoch, lr_decay_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, power\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#train\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_loss,train_iou,train_acc\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m train_iou \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(train_iou)\n\u001b[0;32m     12\u001b[0m train_iou_list\u001b[38;5;241m.\u001b[39mappend(train_iou)\n",
      "Cell \u001b[1;32mIn[2], line 63\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_idx)\n\u001b[0;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), targets\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m---> 63\u001b[0m iou_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmIoU\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pixel_accuracy(outputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#BackPropagation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mmIoU\u001b[1;34m(pred_mask, mask, smooth, n_classes)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmIoU\u001b[39m(pred_mask, mask, smooth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-10\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 17\u001b[0m         pred_mask \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m         pred_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(pred_mask, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m         pred_mask \u001b[38;5;241m=\u001b[39m pred_mask\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Federico\\Desktop\\Universita\\1_Magistrale\\2_semestre\\MLDL\\Env\\Lib\\site-packages\\torch\\nn\\functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "epoch_beginning = 0\n",
    "epochs = 1\n",
    "for epoch in range(epoch_beginning,epochs):\n",
    "    n_epoch = epoch+1\n",
    "    l_rate = poly_lr_scheduler(optimizer, init_lr=start_lr , iter=epoch, lr_decay_iter=1, max_iter=50, power=0.9)\n",
    "    #train\n",
    "    train_loss,train_iou,train_acc=train(model, optimizer, train_loader, loss_fn)\n",
    "    train_iou = np.nanmean(train_iou)\n",
    "    train_iou_list.append(train_iou)\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    #save model\n",
    "    if n_epoch%5 == 0 or n_epoch==epochs:\n",
    "        model_name = f\"bisenet_GTA5_bs{bs}_epoch{n_epoch}_weights.pth\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "    #test    \n",
    "    test_loss,class_iou,test_acc = test(model, val_loader, loss_fn)\n",
    "    test_iou = np.nanmean(class_iou)\n",
    "    test_iou_list.append(test_iou)\n",
    "    class_iou_list.append(class_iou)\n",
    "    test_acc_list.append(test_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    f = open(\"train_iou_list.txt\", \"a\")\n",
    "    f.write(str(train_iou)+ \"\\n\")\n",
    "    f.close()\n",
    "    f = open(\"test_iou_list.txt\", \"a\")\n",
    "    f.write(str(test_iou)+ \"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    print(f\"Epoch: {n_epoch}\")\n",
    "    print(f\"- Train Acc: {train_acc:.3f}\")\n",
    "#     print(f\"- Train Loss: {test_loss:.3f}\")\n",
    "    print(f\"- Train mIoU: {train_iou:.3f}\\n\")\n",
    "    print(f\"- Test Acc: {test_acc:.3f}\")\n",
    "    print(f\"- Test Loss: {test_loss:.3f}\")\n",
    "    print(f\"- Test mIoU: {test_iou:.3f}\")\n",
    "    if n_epoch==1 or n_epoch == epochs:\n",
    "        print(f\"- Iou per Class: {class_iou}\")\n",
    "    print(\"__________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
